#!/usr/bin/env python2

#Created by Bruno de Medeiros July 2016
#This script takes as input a *.unlinked_snps file generated by pyRAD
#and outputs a nexus file.
#Optionally, it adds populations to species names, if a CSV file
#with columns 'sample' and 'population' are provided
#The goal is to use it as input file to SNAPP

from collections import Counter, defaultdict
from warnings import warn
import random
#import sys

#function to unpack ambiguity codes
def unpack_IUPAC(char):
    char = char.upper()
    seqdict = {"R":["G","A"],
         "K":["G","T"],
         "S":["G","C"],
         "Y":["T","C"],
         "W":["T","A"],
         "M":["C","A"],
         "A":["A"],
         "T":["T"],
         "G":["G"],
         "C":["C"],
         "N":["?"],
         "-":["?"]}
    return set(seqdict[char])



#function to recode alignment column
#assuming N is missing data and any character not ATCG is heterozygous
#gaps will be transformed to missing data too
def recode_to_snapp(column,randomize_02=False):
    column_translated = [unpack_IUPAC(c) for c in column]
    all_nucs = set()
    for c in column_translated:
        all_nucs.update(c)
    all_nucs.difference_update('?')
    if len(all_nucs) > 2:
        warn('Alignment column with >2 alleles removed')
        return None
    if len(all_nucs) < 2:
        warn('Monomorphic alignment column removed')
        return None

    column = [''.join(sorted(c)) for c in column_translated]
    states = set(column)
    all_string = str()
    for c in column:
        if len(c) == 1 and c in 'ATCG':
            all_string += 2 * c
        if len(c) == 2:
            all_string += c

    #create a translation dict from ATCG to 0-2
    counts = Counter(all_string)
    nuc_counts = Counter({i:j for i,j in counts.iteritems() if i in 'ATCG'}).most_common()
    most_common = nuc_counts[0][0]
    translation = {most_common:0,'?':'?'}
    least_common = nuc_counts[1][0]
    translation.update({least_common:2})

    states.difference_update(translation.keys())
    try:
        translation.update({list(states)[0]:1}) #at this point, the only element left in the states set is the heterozygous state, if any
    except IndexError:
        pass

    translated = [translation[i] for i in column]
    
    #this will reverse 0 and 2s randomly, if required
    if randomize_02 and bool(random.getrandbits(1)):
        rev_dict = {0:2, 1:1, 2:0, "?":"?"}
        translated = [rev_dict[i] for i in translated]
        
    return translated

if __name__ == "__main__":
    import argparse, pandas, os
    from Bio import AlignIO
    from Bio.Nexus.Nexus import Nexus


    #first, parse arguments
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('-i', '--input', help = 'path to *.unlinked_snps file')
    parser.add_argument('-p', '--popfile', help = 'path to population assignment file in pyrad format')
    parser.add_argument('-t', '--table', help = 'path to csv table with population information')
    parser.add_argument('-s', '--sample-field', help = 'name of column with sample names in csv table', default = 'sample')
    parser.add_argument('-g', '--population-field', help = 'name of column with population names in csv table', default = 'population')
    parser.add_argument('-f', '--filter', help = 'filter loci to only those found across all populations', action = 'store_true')
    parser.add_argument('-n', '--phylonet', help = 'add PHYLONET block with population assignments', action = 'store_true')
    parser.add_argument('-r', '--randomize', help = 'randomize alle labels, so that counts of 0 and 2 are approximately the same', action = 'store_true')
    
    args = parser.parse_args()    


    #read input alignment
    alignment = AlignIO.read(open(args.input),'phylip-relaxed')
    
    if args.popfile is not None != args.table is not None:
        raise Exception('Provide either popfile or table.')
    
    

    #add populations to species names, if file with population provided
    #if some sample not in population file, warn ans skip
    to_remove = []
    if args.popfile:
        with open(args.popfile, 'r') as popfile:
            samp2pop = dict()    
            for line in popfile:
                line = line.split('#')[0]
                try:
                    sample, pop =  line.split()
                except:
                    break
                if not sample or not pop:
                    break
                else:
                    samp2pop[sample] = pop
        for i in xrange(len(alignment)):
            try:
                new_name = alignment[i].name + '_' + samp2pop[alignment[i].name]
                alignment[i].id = new_name
            except IndexError:
                to_remove.append(i)
                warn('Sample not in population file removed: ' + alignment[i].name)
       
                
    elif args.table:
        pop_table = pandas.read_csv(args.table)
        for i in xrange(len(alignment)):
            try:
                new_name = alignment[i].name + '_' + \
                        pop_table.loc[pop_table[args.sample_field] == alignment[i].name, args.population_field].iloc[0]
                alignment[i].id = new_name
            except IndexError:
                to_remove.append(i)
                warn('Sample not in population file removed: ' + alignment[i].name)
    
    if to_remove:
        #print alignment
        #print len(alignment)
        for i in sorted(to_remove, reverse = True):
            #print i
            new_alignment = alignment[:i]
            new_alignment.extend(alignment[(i+1):])
            alignment = new_alignment
        #print len(alignment)
                
    
            
    #filter dataset
    if args.filter:
        #print alignment[i].id
        pops = [alignment[i].id.split('_')[-1] for i in range(len(alignment))]
        #print pops
        while True:
            #print alignment
            for i in range(alignment.get_alignment_length()):
                pop_dict = defaultdict(int)
                for j in range(len(pops)):
                    if not alignment[j,i] in ['-','N']:
                        pop_dict[pops[j]] += 1
                if set(pops) - set(pop_dict.keys()): #if not all populations present for a locus, drop an restart search
                    alignment = alignment[:,:i] + alignment[:,i+1:]
                    break
            else: #if for loop runs through the end, break while loop
                break
                        
            
            
                
    #recode input to 0-2
    column_list = [recode_to_snapp(alignment[:,i], args.randomize) for i in xrange(len(alignment[0]))]
    seq_list = [seq for seq in alignment] #transforming to sequence list to enable removing columns from alignment
    for i in xrange(len(seq_list)):
        seq_list[i].seq = ''.join([str(column[i]) for column in column_list if column is not None])
        

    #create a nexus object to hold the data
    align_nexus = Nexus()
    align_nexus.datatype = 'integerdata'
    align_nexus.symbols = '012'
    for seq in seq_list:
        align_nexus.add_sequence(name =seq.id, sequence = seq.seq)

    #write output as nexus
    outpath = os.path.splitext(os.path.basename(args.input))[0] + '.nex'
    align_nexus.write_nexus_data(outpath)
    
    #add population assignment if requested
    with open(outpath, 'a') as outfile:
        pop_dict = defaultdict(list)
        for seqr in alignment:
            samp = seqr.id
            pop = samp.split('_')[-1]
            pop_dict[pop].append(samp)
        
        #print pop_dict
        taxalist = '(' + ','.join([seqr.id for seqr in alignment]) + ')'
        taxonmap = '<' + ';'.join([pop + ':' + ','.join(samps) 
                                   for pop, samps in pop_dict.iteritems()]) + '>'
        
        
        outfile.write('\n')
        outfile.write('begin phylonet;\n')
        outfile.write('MLE_BiMarkers -pseudo -diploid -op -pi0 0.5 -sd 154871 -mr 10 -taxa ')
        outfile.write(taxalist)
        outfile.write(' -tm ')
        outfile.write(taxonmap)
        outfile.write(';\nend;')
        
